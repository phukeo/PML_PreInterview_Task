{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"PML_Logo1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Interview Visualisation Task - Benjamin O'Driscoll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference Site: Western Channel Observatory <br> Coastal Station: L4 <br> Instrument: CTD \n",
    "\n",
    "The aim of this notebook is to visualise data from the WCO, L4, CTD in-situ time series data file.\n",
    "<br>\n",
    "A CTD instrument is used to take measurements of several variables over depth for the study of seasonal and\n",
    "annual trends. <br>\n",
    "A link to the data used in this notebook is provided [HERE](https://www.dropbox.com/s/nz2xotqglirl0wy/L4_CTDf_ODV_format.txt?dl=0)\n",
    "\n",
    "#### Use of the Bokeh Library\n",
    "\n",
    "The visualisation package used in this notebook is the Bokeh library. It offers the following advantages for the benefit of the end user \n",
    "\n",
    "- Interactive Plots \n",
    "- Fully Cusotmisable Appearances\n",
    "- Plots which are Linked Together\n",
    "- Hover tools which offer Additional Information relating to Data\n",
    "- Automatic HTML Generation for Easier Webpage Integration \n",
    "\n",
    "\n",
    "#### Note to the User\n",
    "\n",
    "Although this notebook has been designed to be scalable there are some nasty hardcoded parts which should be removed for future evolutions. These parts are highlighted at the end of the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1 - Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules required for Jupyter notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "\n",
    "from bokeh.plotting import figure,show, output_file, ColumnDataSource\n",
    "from bokeh.models import Range1d, LinearColorMapper, DateRangeSlider, RangeSlider, CDSView, CustomJSFilter, CustomJS, BoxAnnotation, ColorBar\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.layouts import row, gridplot, column, layout\n",
    "\n",
    "from bokeh.core.validation import silence\n",
    "from bokeh.core.validation.warnings import FIXED_SIZING_MODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 - Define Functions\n",
    "\n",
    "These are functions that are called throughout this notebook are defined here so that the flow of the notebook is not interupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnNames(name):\n",
    "    \n",
    "    \"\"\" Format of the raw text file has the name and unit of the header on two rows.\n",
    "    During import using pandas, dataFrame forms these into a multiple index.\n",
    "    When these are flattened into 1 header name there is no parenthesis around the units.\n",
    "    \n",
    "    This function changes the name of the column headers. \n",
    "    FROM: \"NAME UNIT\"\n",
    "    TO: \"NAME (UNIT)\"\n",
    "    \"\"\"\n",
    "    # Select the NAME\n",
    "    firstPart=name[0:name.find(' ')+1:]\n",
    "    # Select the UNIT\n",
    "    secondPart=name[name.find(' ')+1:]\n",
    "    # Add parentheses around the UNIT \n",
    "    newName=firstPart+'('+secondPart+')'\n",
    "    \n",
    "    return newName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateTimeCorrection(dateTimeEntry):\n",
    "    \"\"\"Format of most date/time stamps are 23 characters long.\n",
    "    There are a few date/time stamps that are 24 characters long as they have an additional\n",
    "    character in the 's' part of the timestamp.\n",
    "    \n",
    "    This function truncates the length of the timestamp to 23 characters long.\n",
    "    This prevents errors handling these values downstream\n",
    "    \n",
    "    FROM: \"2002-01-07T12:00:000.000\"\n",
    "    TO: \"2002-01-07T12:00:00.000\"    \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(dateTimeEntry) > 23:\n",
    "        # If is is larger than truncate the length of the date/time stamp\n",
    "        dateTimeEntry = dateTimeEntry[0:19] + \".000\"\n",
    "        return dateTimeEntry\n",
    "    else:\n",
    "        # Do nothing\n",
    "        return (dateTimeEntry)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1 - Data Import\n",
    "\n",
    "Bring the data from its raw form into this notebook in an efficient manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to tell pandas what the datatype of each column is. If we didn't then the pandas\n",
    "# would have to make a guess for each column which is inefficient on memory. \n",
    "# datetypeDict is a dictionary which warns pandas what to expect when importing\n",
    "datatypeDict={'Lat':float, 'Lon':float, 'Depth':float,\n",
    "              'Temperature':float, 'Transmission':float,\n",
    "              'PAR':float, 'Fluorescence':float, 'Density':float,\n",
    "              'Oxygen':float, 'Salinity':float, 'Turbidity':float} \n",
    "\n",
    "# Need to explicitly tell pandas the delimiter is whitespace and headers are on two rows.\n",
    "# Dictionary defined above is used to improve memory efficiency.  \n",
    "# Commented out line below was used for development purposes. It uses a file with only ~2500 rows \n",
    "# dataFrame = pd.read_csv('L4_CTDf_ODV_formatSmall.txt', delim_whitespace=True,\n",
    "#                         dtype=datatypeDict, header=[0,1])\n",
    "dataFrame = pd.read_csv('L4_CTDf_ODV_format.txt', delim_whitespace=True,\n",
    "                        dtype=datatypeDict, header=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Cruise</th>\n",
       "      <th>Station</th>\n",
       "      <th>Type</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>PAR</th>\n",
       "      <th>Fluorescence</th>\n",
       "      <th>Density</th>\n",
       "      <th>Oxygen</th>\n",
       "      <th>Salinity</th>\n",
       "      <th>Turbidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>CCC</th>\n",
       "      <th>SS</th>\n",
       "      <th>T</th>\n",
       "      <th>yyyy-mm-ddThh:mm:ss.sss</th>\n",
       "      <th>degN</th>\n",
       "      <th>degE</th>\n",
       "      <th>m</th>\n",
       "      <th>degC</th>\n",
       "      <th>%</th>\n",
       "      <th>uE/m2/s</th>\n",
       "      <th>volts</th>\n",
       "      <th>kg/m3</th>\n",
       "      <th>uM</th>\n",
       "      <th>PSU</th>\n",
       "      <th>NTU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WCO</td>\n",
       "      <td>L4</td>\n",
       "      <td>c</td>\n",
       "      <td>2002-01-07T12:00:00.000</td>\n",
       "      <td>50.25174</td>\n",
       "      <td>-4.22056</td>\n",
       "      <td>48.0</td>\n",
       "      <td>10.6825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0286</td>\n",
       "      <td>1027.2241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.2221</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WCO</td>\n",
       "      <td>L4</td>\n",
       "      <td>c</td>\n",
       "      <td>2002-01-07T12:00:00.000</td>\n",
       "      <td>50.25174</td>\n",
       "      <td>-4.22056</td>\n",
       "      <td>47.5</td>\n",
       "      <td>10.6827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0396</td>\n",
       "      <td>1027.2219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.2222</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WCO</td>\n",
       "      <td>L4</td>\n",
       "      <td>c</td>\n",
       "      <td>2002-01-07T12:00:00.000</td>\n",
       "      <td>50.25174</td>\n",
       "      <td>-4.22056</td>\n",
       "      <td>47.0</td>\n",
       "      <td>10.6826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9936</td>\n",
       "      <td>1027.2198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.2224</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WCO</td>\n",
       "      <td>L4</td>\n",
       "      <td>c</td>\n",
       "      <td>2002-01-07T12:00:00.000</td>\n",
       "      <td>50.25174</td>\n",
       "      <td>-4.22056</td>\n",
       "      <td>46.5</td>\n",
       "      <td>10.6828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0387</td>\n",
       "      <td>1027.2175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.2224</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WCO</td>\n",
       "      <td>L4</td>\n",
       "      <td>c</td>\n",
       "      <td>2002-01-07T12:00:00.000</td>\n",
       "      <td>50.25174</td>\n",
       "      <td>-4.22056</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.6826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0234</td>\n",
       "      <td>1027.2152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.2224</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cruise Station Type                 DateTime       Lat      Lon Depth  \\\n",
       "     CCC      SS    T  yyyy-mm-ddThh:mm:ss.sss      degN     degE     m   \n",
       "0    WCO      L4    c  2002-01-07T12:00:00.000  50.25174 -4.22056  48.0   \n",
       "1    WCO      L4    c  2002-01-07T12:00:00.000  50.25174 -4.22056  47.5   \n",
       "2    WCO      L4    c  2002-01-07T12:00:00.000  50.25174 -4.22056  47.0   \n",
       "3    WCO      L4    c  2002-01-07T12:00:00.000  50.25174 -4.22056  46.5   \n",
       "4    WCO      L4    c  2002-01-07T12:00:00.000  50.25174 -4.22056  46.0   \n",
       "\n",
       "  Temperature Transmission     PAR Fluorescence    Density Oxygen Salinity  \\\n",
       "         degC            % uE/m2/s        volts      kg/m3     uM      PSU   \n",
       "0     10.6825          NaN     NaN       2.0286  1027.2241    NaN  35.2221   \n",
       "1     10.6827          NaN     NaN       2.0396  1027.2219    NaN  35.2222   \n",
       "2     10.6826          NaN     NaN       1.9936  1027.2198    NaN  35.2224   \n",
       "3     10.6828          NaN     NaN       2.0387  1027.2175    NaN  35.2224   \n",
       "4     10.6826          NaN     NaN       2.0234  1027.2152    NaN  35.2224   \n",
       "\n",
       "  Turbidity  \n",
       "        NTU  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a sneek peak at the data\n",
    "display(dataFrame.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 - Data Transformation\n",
    "Transform the data so that it is in a format that can be handled easily downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line joins the NAME header with the UNIT header which \n",
    "# simplifies the dataFrame for manipulation as only calling one header is easier \n",
    "dataFrame.columns=dataFrame.columns.map(' '.join) \n",
    "\n",
    "# This list comprehension builds up a new list of columns names by adding the \n",
    "# UNIT values into parantheses \n",
    "newColumnNames=[columnNames(i) for i in dataFrame.columns] \n",
    "\n",
    "# This new list is then set as the column names\n",
    "dataFrame.columns=newColumnNames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the times where the length of the timestamp is erroneously not 23.\n",
    "# These will form part of the output to feedback to device owner. \n",
    "longTimes=dataFrame[dataFrame['DateTime (yyyy-mm-ddThh:mm:ss.sss)'].apply(lambda x: len(x)>23)].iloc[:,3]\n",
    "errorFrameTimes=longTimes.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell loops over the column values and truncates them to the correct size\n",
    "dataFrame['DateTime (yyyy-mm-ddThh:mm:ss.sss)'] = [dateTimeCorrection(entry) for entry in dataFrame['DateTime (yyyy-mm-ddThh:mm:ss.sss)']]\n",
    "\n",
    "# Line below adds another column to the dataFrame which copies all of the string values.\n",
    "# This makes accessing date/time stamp values easier when hovering in later plots. \n",
    "dataFrame['DateTimeLabels']=dataFrame['DateTime (yyyy-mm-ddThh:mm:ss.sss)'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DateTime column is imported as string which will cause problems downstream. \n",
    "# Convert this column to DateTime datatype here:\n",
    "dataFrame.iloc[:,3] =  pd.to_datetime(dataFrame.iloc[:,3], format='%Y-%m-%dT%H:%M:%S.%f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cruise (CCC)</th>\n",
       "      <th>Station (SS)</th>\n",
       "      <th>Type (T)</th>\n",
       "      <th>DateTime (yyyy-mm-ddThh:mm:ss.sss)</th>\n",
       "      <th>Lat (degN)</th>\n",
       "      <th>Lon (degE)</th>\n",
       "      <th>Depth (m)</th>\n",
       "      <th>Temperature (degC)</th>\n",
       "      <th>Transmission (%)</th>\n",
       "      <th>PAR (uE/m2/s)</th>\n",
       "      <th>Fluorescence (volts)</th>\n",
       "      <th>Density (kg/m3)</th>\n",
       "      <th>Oxygen (uM)</th>\n",
       "      <th>Salinity (PSU)</th>\n",
       "      <th>Turbidity (NTU)</th>\n",
       "      <th>DateTimeLabels</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WCO</td>\n",
       "      <td>L4</td>\n",
       "      <td>c</td>\n",
       "      <td>2002-01-07 12:00:00</td>\n",
       "      <td>50.25174</td>\n",
       "      <td>-4.22056</td>\n",
       "      <td>48.0</td>\n",
       "      <td>10.6825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0286</td>\n",
       "      <td>1027.2241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.2221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-01-07T12:00:00.000</td>\n",
       "      <td>1.010405e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WCO</td>\n",
       "      <td>L4</td>\n",
       "      <td>c</td>\n",
       "      <td>2002-01-07 12:00:00</td>\n",
       "      <td>50.25174</td>\n",
       "      <td>-4.22056</td>\n",
       "      <td>47.5</td>\n",
       "      <td>10.6827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0396</td>\n",
       "      <td>1027.2219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.2222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-01-07T12:00:00.000</td>\n",
       "      <td>1.010405e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WCO</td>\n",
       "      <td>L4</td>\n",
       "      <td>c</td>\n",
       "      <td>2002-01-07 12:00:00</td>\n",
       "      <td>50.25174</td>\n",
       "      <td>-4.22056</td>\n",
       "      <td>47.0</td>\n",
       "      <td>10.6826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9936</td>\n",
       "      <td>1027.2198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.2224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-01-07T12:00:00.000</td>\n",
       "      <td>1.010405e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WCO</td>\n",
       "      <td>L4</td>\n",
       "      <td>c</td>\n",
       "      <td>2002-01-07 12:00:00</td>\n",
       "      <td>50.25174</td>\n",
       "      <td>-4.22056</td>\n",
       "      <td>46.5</td>\n",
       "      <td>10.6828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0387</td>\n",
       "      <td>1027.2175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.2224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-01-07T12:00:00.000</td>\n",
       "      <td>1.010405e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WCO</td>\n",
       "      <td>L4</td>\n",
       "      <td>c</td>\n",
       "      <td>2002-01-07 12:00:00</td>\n",
       "      <td>50.25174</td>\n",
       "      <td>-4.22056</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.6826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0234</td>\n",
       "      <td>1027.2152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.2224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-01-07T12:00:00.000</td>\n",
       "      <td>1.010405e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cruise (CCC) Station (SS) Type (T) DateTime (yyyy-mm-ddThh:mm:ss.sss)  \\\n",
       "0          WCO           L4        c                2002-01-07 12:00:00   \n",
       "1          WCO           L4        c                2002-01-07 12:00:00   \n",
       "2          WCO           L4        c                2002-01-07 12:00:00   \n",
       "3          WCO           L4        c                2002-01-07 12:00:00   \n",
       "4          WCO           L4        c                2002-01-07 12:00:00   \n",
       "\n",
       "   Lat (degN)  Lon (degE)  Depth (m)  Temperature (degC)  Transmission (%)  \\\n",
       "0    50.25174    -4.22056       48.0             10.6825               NaN   \n",
       "1    50.25174    -4.22056       47.5             10.6827               NaN   \n",
       "2    50.25174    -4.22056       47.0             10.6826               NaN   \n",
       "3    50.25174    -4.22056       46.5             10.6828               NaN   \n",
       "4    50.25174    -4.22056       46.0             10.6826               NaN   \n",
       "\n",
       "   PAR (uE/m2/s)  Fluorescence (volts)  Density (kg/m3)  Oxygen (uM)  \\\n",
       "0            NaN                2.0286        1027.2241          NaN   \n",
       "1            NaN                2.0396        1027.2219          NaN   \n",
       "2            NaN                1.9936        1027.2198          NaN   \n",
       "3            NaN                2.0387        1027.2175          NaN   \n",
       "4            NaN                2.0234        1027.2152          NaN   \n",
       "\n",
       "   Salinity (PSU)  Turbidity (NTU)           DateTimeLabels     Timestamp  \n",
       "0         35.2221              NaN  2002-01-07T12:00:00.000  1.010405e+12  \n",
       "1         35.2222              NaN  2002-01-07T12:00:00.000  1.010405e+12  \n",
       "2         35.2224              NaN  2002-01-07T12:00:00.000  1.010405e+12  \n",
       "3         35.2224              NaN  2002-01-07T12:00:00.000  1.010405e+12  \n",
       "4         35.2224              NaN  2002-01-07T12:00:00.000  1.010405e+12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell converts the DateTime column into a column of Timestamps. \n",
    "# These are easier to handle downstream for visualisations\n",
    "\n",
    "timeStampList=[datetime.timestamp(entry)*1000 for entry in dataFrame['DateTime (yyyy-mm-ddThh:mm:ss.sss)']]\n",
    "dataFrame['Timestamp'] = pd.DataFrame(timeStampList)\n",
    "\n",
    "display(dataFrame.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "### Selecting Variables of Interest\n",
    "\n",
    "Determine a relationship between variables that could be interesting to plot.\n",
    "<br>Use the `corr()` method to automatically determine correlations between two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Turbidity (NTU)  Fluorescence (volts)    0.503237\n",
       "Salinity (PSU)   Density (kg/m3)         0.900308\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The corr() method determines the (Pearson) correlation between all columns of a dataFrame \n",
    "correlatedTable=dataFrame.corr()\n",
    "\n",
    "# Unstack from dataFrame to Series\n",
    "correlatedPairs=correlatedTable.unstack()\n",
    "\n",
    "# Sort them in order and then drop all NaN values as we are not interested in these\n",
    "sortedPairs = correlatedPairs.sort_values(kind=\"quicksort\") \n",
    "sortedPairsNoNan=sortedPairs.dropna()\n",
    "\n",
    "# Using the .corr() method will give the value of 1 along the diagonals of the \n",
    "# where each column is correlated 'perfectly' with itself. We want to ignore these.\n",
    "# To do this, we index the values between 0.5 and 1.\n",
    "\n",
    "strongPositiveCorrelationsRaw=sortedPairsNoNan[sortedPairsNoNan.between(0.5,1, inclusive=False)]\n",
    "\n",
    "# Since every row is correlated with every column and every column is correlated with \n",
    "# every row, we get repeated values. Line below selects remove duplicate values.\n",
    "strongPositiveCorrelations=strongPositiveCorrelationsRaw[0:-1:2]\n",
    "\n",
    "# Display all variables with Pearson correlation between 0.5 and 1\n",
    "display(strongPositiveCorrelations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "### Finding Errors\n",
    "\n",
    "Now that we have determined the variables that we are interested in we should conduct statistical analysis to determine outliers and errors which can be reported back to the sensor owners. <br>\n",
    "This analysis will also feed into any future plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to look to see if there are errors in the Density data\n",
    "data=dataFrame['Density (kg/m3)']\n",
    "\n",
    "# Simple Z-score to determine the number of standard deviations values are away from mean.\n",
    "# Need to conduct the abs since we can have values lower and higher than the mean. \n",
    "zScore = np.abs(stats.zscore(data))\n",
    "\n",
    "# Determine an array with index values where the abs(z-score) is greater than 3.  \n",
    "zArray=np.where(zScore>3) \n",
    "\n",
    "densityStats={'Mean':np.mean(data), \n",
    "             'StandardDeviation':np.std(data),\n",
    "             'UpperLimit': np.mean(data)+(3*np.std(data)),\n",
    "             'LowerLimit': np.mean(data)-(3*np.std(data))}\n",
    "\n",
    "# Create a dataFrame for these erroneous values.\n",
    "# These will form part of the output to feedback to device owner.\n",
    "errorFrameDensity=dataFrame.iloc[zArray[0],[3,11]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As above but for Salinity\n",
    "data=dataFrame['Salinity (PSU)']\n",
    "\n",
    "zScore = np.abs(stats.zscore(data))\n",
    "zArray = np.where(zScore>3)\n",
    "\n",
    "salinityStats={'Mean':np.mean(data), \n",
    "             'StandardDeviation':np.std(data),\n",
    "             'UpperLimit': np.mean(data)+(3*np.std(data)),\n",
    "             'LowerLimit': np.mean(data)-(3*np.std(data))}\n",
    "\n",
    "errorFrameSalinity=dataFrame.iloc[zArray[0],[3,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As above but for Temperature\n",
    "data=dataFrame['Temperature (degC)']\n",
    "\n",
    "zScore = np.abs(stats.zscore(data))\n",
    "zArray = np.where(zScore>3)\n",
    "\n",
    "temperatureStats={'Mean':np.mean(data), \n",
    "             'StandardDeviation':np.std(data),\n",
    "             'UpperLimit': np.mean(data)+(3*np.std(data)),\n",
    "             'LowerLimit': np.mean(data)-(3*np.std(data))}\n",
    "\n",
    "errorFrameTemperature=dataFrame.iloc[zArray[0],[3,7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting Errors\n",
    "\n",
    "Export error dataFrame so that the sensor owner can investigate potential problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output all of the errorFrames into indicdual CSV to report back to sensor owner. \n",
    "errorFrameDensity.to_csv('Density_Errors.csv')\n",
    "errorFrameSalinity.to_csv('Salinity_Errors.csv')\n",
    "errorFrameTemperature.to_csv('Temperature_Errors.csv')\n",
    "errorFrameTimes.to_csv('Time_Errors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Data Visualisation\n",
    "### Stage 1 - Data/Plot Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ColumnDataSource for Bokeh Wizardry. This allows plots to be interactive and linked together.\n",
    "source=ColumnDataSource(dataFrame)\n",
    "\n",
    "# We want to include the temperature to see if it plays an impact on the variables\n",
    "# This could be relationship could be hidden by use of linear correlations only\n",
    "# Choose the palette first, then select max and min values from temperatureStats dictionary\n",
    "color_mapper = LinearColorMapper(palette='Magma256', low=temperatureStats['LowerLimit'],\n",
    "                                 high=temperatureStats['UpperLimit'])\n",
    "Colors = {'field': 'Temperature (degC)', 'transform': color_mapper}\n",
    "\n",
    "# We want further information to pop up once the user mouses over the data points. \n",
    "# To do this we create Tooltips which will facilitate hover actions when mousing over data points.\n",
    "# This will display the Date, Temperature and Depth to the user on hover.\n",
    "toolTips = [('DateTime ','@{DateTimeLabels}'),\n",
    "           ('Temperature ','@{Temperature (degC)}'),\n",
    "           ('Depth ','@{Depth (m)}')] \n",
    "\n",
    "# Setup the tools that will be common to plots\n",
    "tools=\"pan,lasso_select,box_select,hover,zoom_in,zoom_out, box_zoom, wheel_zoom,reset,save\"\n",
    "\n",
    "# Possible to change the marker size based on the depth here. \n",
    "# For larger data files this is not suitable so comment out the 1st line. \n",
    "Sizes=('Depth (m)')\n",
    "# Sizes=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2 - Create Interactive Plots and Link Widgets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns of interest\n",
    "strX1='Density (kg/m3)'\n",
    "strY1='Salinity (PSU)'\n",
    "strZ1='Depth (m)'\n",
    "strDT='DateTime (yyyy-mm-ddThh:mm:ss.sss)'\n",
    "\n",
    "# Line Below Produces HTML output suitable for inclusion onto a website\n",
    "output_file('WCO-CTD-L4_Summaryfile.html')\n",
    "\n",
    "\n",
    "# Initialise FILTER Widgets here\n",
    "# These are widgets that filter the data for the user depending on input.\n",
    "# They are treated different to other widgets and must sit here\n",
    "dateSlider = DateRangeSlider(title=\"Filter Data by Date\",\n",
    "                             value=(min(dataFrame[strDT]), ((dataFrame[strDT])[1380])),\n",
    "                             start=min(dataFrame[strDT]), end=max(dataFrame[strDT]))\n",
    "depthSlider = RangeSlider(title=\"Filter Data by Depth (m)\",\n",
    "                          value=(min(dataFrame[strZ1]), (max(dataFrame[strZ1]))),\n",
    "                          start=min(dataFrame[strZ1]), end=max(dataFrame[strZ1]))\n",
    "\n",
    "# Create customJS filter which is used to select data on interest\n",
    "# when the user moves the DateRange slider\n",
    "dateFilter = CustomJSFilter(args=dict(slider=dateSlider), code=\"\"\"\n",
    "    const indices = []\n",
    "    const date_from = slider.value[0];\n",
    "    const date_to = slider.value[1]\n",
    "    for (var i = 0; i < source.get_length(); i++) {\n",
    "        if ((source.data['Timestamp'][i] <= date_to) && (source.data['Timestamp'][i] >= date_from)) {\n",
    "            indices.push(true)\n",
    "        } else {\n",
    "            indices.push(false)\n",
    "        }\n",
    "    }\n",
    "    return indices\n",
    "\"\"\")\n",
    "\n",
    "# Create customJS filter which is used to select data on interest\n",
    "# when the user moves the DepthRange slider\n",
    "depthFilter = CustomJSFilter(args=dict(slider1=depthSlider), code=\"\"\"\n",
    "    const indices = []\n",
    "    const depth_from = slider1.value[0];\n",
    "    const depth_to = slider1.value[1]\n",
    "    for (var i = 0; i < source.get_length(); i++) {\n",
    "        if ((source.data['Depth (m)'][i] <= depth_to) && (source.data['Depth (m)'][i] >= depth_from)) {\n",
    "            indices.push(true)\n",
    "        } else {\n",
    "            indices.push(false)\n",
    "        }\n",
    "    }\n",
    "    return indices\n",
    "\"\"\")\n",
    "\n",
    "# Code below detects a change when the sliders are moved which then forces the CustomJSFilters to run\n",
    "dateSlider.js_on_change('value', CustomJS(args=dict(source=source), code=\"\"\"\n",
    "   source.change.emit()\n",
    "\"\"\"))\n",
    "depthSlider.js_on_change('value', CustomJS(args=dict(source=source), code=\"\"\"\n",
    "   source.change.emit()\n",
    "\"\"\"))\n",
    "\n",
    "# Think of this View as the original dataFrame filtered within the ranges of the sliders.\n",
    "# This view is then used to update the plots\n",
    "view = CDSView(source=source, filters=[dateFilter,depthFilter])\n",
    "\n",
    "\n",
    "# Setup the plots below\n",
    "# Box below indicates the region within 3 standard deviations for Density and Salinity. \n",
    "box = BoxAnnotation(bottom=salinityStats['LowerLimit'],top=salinityStats['UpperLimit'], \n",
    "                    right=densityStats['UpperLimit'], left=densityStats['LowerLimit'], \n",
    "                    fill_alpha=0.05, fill_color='#0072B2')\n",
    "\n",
    "qr0=figure(title='Filtered Data- Autoscale', tools=tools,tooltips=toolTips)\n",
    "qr0.add_layout(box)\n",
    "qr0.scatter(x=strX1,y=strY1,source=source, size=4, color=Colors, hover_color='green',view=view)\n",
    "qr0.xaxis.axis_label = strX1\n",
    "qr0.yaxis.axis_label = strY1\n",
    "\n",
    "qr2=figure(title='Filtered Data - Within 3SD',tools=tools,tooltips=toolTips)\n",
    "qr2.scatter(x=strX1,y=strY1,source=source, size=4, color=Colors, hover_color='green', view=view)\n",
    "qr2.x_range=Range1d(densityStats['LowerLimit'],densityStats['UpperLimit'])\n",
    "qr2.y_range=Range1d(salinityStats['LowerLimit'],salinityStats['UpperLimit'])\n",
    "qr2.xaxis.axis_label = strX1\n",
    "qr2.yaxis.axis_label = strY1\n",
    "qr2.add_layout(box)\n",
    "\n",
    "qr3=figure(title='Unfiltered Data - User View',tools=tools,tooltips=toolTips)\n",
    "points=qr3.scatter(x=strX1,y=strY1,source=source, size=Sizes, color=Colors, hover_color='green')\n",
    "qr3.x_range=Range1d(1024,1028)\n",
    "qr3.y_range=Range1d(32,37)\n",
    "qr3.xaxis.axis_label = strX1\n",
    "qr3.yaxis.axis_label = strY1\n",
    "\n",
    "qr4=figure(title='Filtered Data - User View',tools=tools,tooltips=toolTips)\n",
    "points=qr4.scatter(x=strX1,y=strY1,source=source, size=Sizes, color=Colors, hover_color='green', view=view)\n",
    "qr4.x_range=Range1d(1024,1028)\n",
    "qr4.y_range=Range1d(32,37)\n",
    "qr4.xaxis.axis_label = strX1\n",
    "qr4.yaxis.axis_label = strY1\n",
    "\n",
    "# Initialise the colorBar and add it to two of the plots  \n",
    "colorBar = ColorBar(color_mapper=color_mapper,location=(0, 0),  title='Temp')\n",
    "qr0.add_layout(colorBar,'right')\n",
    "qr3.add_layout(colorBar,'right')\n",
    "\n",
    "# Initialise PLOT RANGE Widgets here\n",
    "# These are widgets that adjust the graphical ranges.\n",
    "# They rely on information from the plots above and therefore must live here\n",
    "densityView= RangeSlider(title=\"Adjust Density (kg/m3) Range View\",step=0.5, \n",
    "                         value=(qr4.x_range.start,qr4.x_range.end), start=1008, end=1028)\n",
    "densityView.js_link(\"value\", qr4.x_range, \"start\", attr_selector=0)\n",
    "densityView.js_link(\"value\", qr4.x_range, \"end\", attr_selector=1)\n",
    "densityView.js_link(\"value\", qr3.x_range, \"start\", attr_selector=0)\n",
    "densityView.js_link(\"value\", qr3.x_range, \"end\", attr_selector=1)\n",
    "\n",
    "salinityView= RangeSlider(title=\"Adjust Salinity (PSU) Range View\",step=0.5, \n",
    "                          value=(qr4.y_range.start,qr4.y_range.end), start=12, end=37)\n",
    "salinityView.js_link(\"value\", qr4.y_range, \"start\", attr_selector=0)\n",
    "salinityView.js_link(\"value\", qr4.y_range, \"end\", attr_selector=1)\n",
    "salinityView.js_link(\"value\", qr3.y_range, \"start\", attr_selector=0)\n",
    "salinityView.js_link(\"value\", qr3.y_range, \"end\", attr_selector=1)\n",
    "\n",
    "# Bring it all together below\n",
    "# Bring all of the widgets together into a layout\n",
    "# Bring the plots and widgets into a layout\n",
    "# Code which silences the FIXED_SIZING_MODE is require since the best place to put the \n",
    "# exact width and height of the widgets is not known. This is a hacky workaround\n",
    "silence(FIXED_SIZING_MODE, True) \n",
    "widgets = column (row(dateSlider,depthSlider),\n",
    "                  row(densityView,salinityView),\n",
    "                  width=200, height=100, sizing_mode='fixed')\n",
    " \n",
    "grid = gridplot(children = [[qr0, qr2], [qr3,qr4],[widgets] ], sizing_mode = 'stretch_both')\n",
    "\n",
    "# Print to screen\n",
    "show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Forward\n",
    "### Hacky Things\n",
    "\n",
    "- `FIXED_SIZING_MODE` Error is silenced. This error is raised during the plotting stage. It is raised because the exact location for the explicit height and width values for the widgets is not known by the author\n",
    "- `dateSlider` Upper value for date has been hardcoded with index of `[1380]` to capture first 6 months \n",
    "\n",
    "### Developments to improve in future evolutions\n",
    "- Analysis\n",
    "    - At the moment the the only trends in the variables analysed are linear correlations by using the `corr()` method. Future iterations should look at non linear relationships.\n",
    "    - Merge errorFrames together so that rows with multiple errors appear on one line only\n",
    "- Interactivity\n",
    "    - Include a Widget for the user to switch dynamic depth sizes on and off\n",
    "    - Include a Widget to scroll through density/salinity data which will filter the data for one month across different years. This will allow the user to see if there are changes year to year for the same month \n",
    "    - Improve the Hover tool so that the long timestamp is removed and only the date is printed to the screen \n",
    "    - Add in an option for the user to export data from the filtered visualisations\n",
    "- Efficiency\n",
    "    - Improve the efficiency of the algorithms used, there is a lag of tens of seconds when updating the charts. This is possibly due to my laptop but I'm sure there are more efficient ways to handle the data\n",
    "    - Replace all list functions with dataframe apply functions\n",
    "- Visualisations\n",
    "    - Replace two colorBars with one that is located on the left hand side but spans the two rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
